{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "torch.Size([32, 2048])\n",
      "Epoch 1/10, Train Loss: 0.6444, Val Loss: 0.5911, Train Acc: 0.0000, Val Acc: 0.0000, Train F1: 0.0770, Val F1: 0.2287\n",
      "Epoch 2/10, Train Loss: 0.5828, Val Loss: 0.5679, Train Acc: 0.0107, Val Acc: 0.0241, Train F1: 0.2225, Val F1: 0.1958\n",
      "Epoch 3/10, Train Loss: 0.5702, Val Loss: 0.5611, Train Acc: 0.0214, Val Acc: 0.0241, Train F1: 0.2137, Val F1: 0.1880\n",
      "Epoch 4/10, Train Loss: 0.5659, Val Loss: 0.5585, Train Acc: 0.0188, Val Acc: 0.0241, Train F1: 0.2150, Val F1: 0.1929\n",
      "Epoch 5/10, Train Loss: 0.5645, Val Loss: 0.5569, Train Acc: 0.0241, Val Acc: 0.0214, Train F1: 0.2595, Val F1: 0.1956\n",
      "Epoch 6/10, Train Loss: 0.5631, Val Loss: 0.5559, Train Acc: 0.0214, Val Acc: 0.0214, Train F1: 0.2555, Val F1: 0.2056\n",
      "Epoch 7/10, Train Loss: 0.5623, Val Loss: 0.5550, Train Acc: 0.0241, Val Acc: 0.0214, Train F1: 0.2186, Val F1: 0.2358\n",
      "Epoch 8/10, Train Loss: 0.5613, Val Loss: 0.5540, Train Acc: 0.0214, Val Acc: 0.0214, Train F1: 0.3140, Val F1: 0.2391\n",
      "Epoch 9/10, Train Loss: 0.5600, Val Loss: 0.5532, Train Acc: 0.0322, Val Acc: 0.0214, Train F1: 0.2734, Val F1: 0.2537\n",
      "Epoch 10/10, Train Loss: 0.5591, Val Loss: 0.5524, Train Acc: 0.0241, Val Acc: 0.0188, Train F1: 0.3052, Val F1: 0.2964\n",
      "test_accuracy: 0.01876675603217158, test_f1: 0.2963894782193751\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, resnet101, resnet152, ResNet50_Weights,ResNet101_Weights, ResNet152_Weights\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizar una matriz de confusión para una etiqueta específica\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from SupportFunc.Loader import MultiLabelImageDataset\n",
    "from SupportFunc.AdaptiveAttention_c1 import AdaptiveAttention, AdaptiveTransformerEncoderLayer\n",
    "from SupportFunc.Visualization import plot_confusion_matrix, plot_train_val_curve\n",
    "\n",
    "class AdaptiveAttentionClassifier(nn.Module):\n",
    "    def __init__(self, image_feature_dim, num_classes):\n",
    "        super(AdaptiveAttentionClassifier, self).__init__()\n",
    "        self.image_embed = nn.Linear(image_feature_dim, 64)\n",
    "        self.transformer_encoder = nn.ModuleList([\n",
    "            AdaptiveTransformerEncoderLayer(d_model=64, nhead=8) for _ in range(1)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_features):\n",
    "        # Proyección de características\n",
    "        image_embeddings = self.image_embed(image_features)\n",
    "\n",
    "        # Pasar por las capas del Transformer\n",
    "        for layer in self.transformer_encoder:\n",
    "            image_embeddings = layer(image_embeddings.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Clasificador final\n",
    "        output = self.mlp(image_embeddings)\n",
    "        return output\n",
    "\n",
    "# Obtener el directorio actual\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory[:-3], 'data')\n",
    "images_directory = os.path.join(data_directory, 'images')\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "image_feature_dim = 2048\n",
    "\n",
    "subset = [os.path.splitext(filename)[0] for filename in os.listdir(images_directory)]\n",
    "print(len(subset))\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Leer y filtrar datos\n",
    "train_1 = pd.read_csv(f'{data_directory}/train_data.csv')\n",
    "test_1 = pd.read_csv(f'{data_directory}/test_data.csv')\n",
    "\n",
    "train_1 = train_1[train_1['ID'].isin(subset[:500])]\n",
    "test_1 = test_1[test_1['ID'].isin(subset[:500])]\n",
    "\n",
    "# Guardar los archivos filtrados\n",
    "train_1.to_csv(f'{data_directory}/train_data_2.csv', encoding = 'utf-8', index=False)\n",
    "train_1.to_csv(f'{data_directory}/test_data_2.csv', encoding = 'utf-8', index=False)\n",
    "\n",
    "# Crear datasets y DataLoaders\n",
    "train_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/train_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "test_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/test_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "#resnet = models.resnet101(weights=ResNet101_Weights.DEFAULT)  # Para ResNet101\n",
    "#resnet = models.resnet152(weights=ResNet152_Weights.DEFAULT)  # Para ResNet152\n",
    "\n",
    "# Congelar todas las capas inicialmente\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar las capas que quieres ajustar (por ejemplo, 'layer4' o 'fc')\n",
    "for param in resnet.layer4.parameters():  # Afinar el bloque final\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Reemplazar la capa final con una capa adaptada a tu número de clases\n",
    "num_classes = train_dataset[0][1].size(0)  # Obtener el número de clases desde el dataset\n",
    "resnet.fc = nn.Identity()\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "model = AdaptiveAttentionClassifier(image_feature_dim=image_feature_dim, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=lr)\n",
    "\n",
    "#Comprobar que las dimensiones de salida de resnet sean consistentes con la siguiente capa\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "image_features = resnet(images)\n",
    "print(image_features.shape)\n",
    "\n",
    "# Listas para almacenar pérdidas y métricas\n",
    "train_losses = list()\n",
    "val_losses = list()\n",
    "train_accuracies = list()\n",
    "val_accuracies = list()\n",
    "train_f1_scores = list()\n",
    "val_f1_scores = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calcular predicciones para métricas\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "        all_train_labels.append(labels.cpu().numpy())\n",
    "        all_train_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para entrenamiento\n",
    "    all_train_labels = np.vstack(all_train_labels)\n",
    "    all_train_preds = np.vstack(all_train_preds)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            image_features = resnet(images).flatten(start_dim=1)\n",
    "            outputs = model(image_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calcular predicciones para métricas\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "            all_val_labels.append(labels.cpu().numpy())\n",
    "            all_val_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para validación\n",
    "    all_val_labels = np.vstack(all_val_labels)\n",
    "    all_val_preds = np.vstack(all_val_preds)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Imprimir métricas\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "        f\"Train Acc: {train_accuracies[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}, \"\n",
    "        f\"Train F1: {train_f1_scores[-1]:.4f}, Val F1: {val_f1_scores[-1]:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # Coloca el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Listas para almacenar etiquetas reales y predicciones\n",
    "all_labels = list()\n",
    "all_preds = list()\n",
    "\n",
    "# Realizar inferencia\n",
    "with torch.no_grad():  # No calculamos gradientes\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Extraer características con ResNet y pasar por el modelo\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        # Aplicar sigmoid para obtener probabilidades\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convertir probabilidades en predicciones binarias (umbral = 0.5)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        # Guardar etiquetas reales y predicciones\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "# Convertir listas a arreglos\n",
    "all_labels = np.vstack(all_labels)  # Etiquetas reales\n",
    "all_preds = np.vstack(all_preds)    # Predicciones\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=1)\n",
    "# Calcular matriz de confusión para cada etiqueta\n",
    "confusion_matrices = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'test_accuracy: {test_accuracy}, test_f1: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "torch.Size([32, 2048])\n",
      "Epoch 1/10, Train Loss: 0.6271, Val Loss: 0.5598, Train Acc: 0.0000, Val Acc: 0.0268, Train F1: 0.0545, Val F1: 0.1157\n",
      "Epoch 2/10, Train Loss: 0.5397, Val Loss: 0.5125, Train Acc: 0.0241, Val Acc: 0.0054, Train F1: 0.1986, Val F1: 0.1582\n",
      "Epoch 3/10, Train Loss: 0.5106, Val Loss: 0.4932, Train Acc: 0.0188, Val Acc: 0.0027, Train F1: 0.1680, Val F1: 0.2024\n",
      "Epoch 4/10, Train Loss: 0.4996, Val Loss: 0.4848, Train Acc: 0.0027, Val Acc: 0.0000, Train F1: 0.1536, Val F1: 0.2000\n",
      "Epoch 5/10, Train Loss: 0.4937, Val Loss: 0.4810, Train Acc: 0.0000, Val Acc: 0.0000, Train F1: 0.2027, Val F1: 0.2008\n",
      "Epoch 6/10, Train Loss: 0.4912, Val Loss: 0.4787, Train Acc: 0.0080, Val Acc: 0.0000, Train F1: 0.2033, Val F1: 0.2008\n",
      "Epoch 7/10, Train Loss: 0.4888, Val Loss: 0.4769, Train Acc: 0.0080, Val Acc: 0.0054, Train F1: 0.2041, Val F1: 0.2025\n",
      "Epoch 8/10, Train Loss: 0.4873, Val Loss: 0.4754, Train Acc: 0.0241, Val Acc: 0.0214, Train F1: 0.2137, Val F1: 0.2071\n",
      "Epoch 9/10, Train Loss: 0.4866, Val Loss: 0.4743, Train Acc: 0.0161, Val Acc: 0.0429, Train F1: 0.2116, Val F1: 0.2164\n",
      "Epoch 10/10, Train Loss: 0.4847, Val Loss: 0.4731, Train Acc: 0.0885, Val Acc: 0.0885, Train F1: 0.2481, Val F1: 0.2294\n",
      "test_accuracy: 0.08847184986595175, test_f1: 0.22942652329749108\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, resnet101, resnet152, ResNet50_Weights,ResNet101_Weights, ResNet152_Weights\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizar una matriz de confusión para una etiqueta específica\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from SupportFunc.Loader import MultiLabelImageDataset\n",
    "from SupportFunc.AdaptiveAttention_c1 import AdaptiveAttention, AdaptiveTransformerEncoderLayer\n",
    "from SupportFunc.Visualization import plot_confusion_matrix, plot_train_val_curve\n",
    "\n",
    "class AdaptiveAttentionClassifier(nn.Module):\n",
    "    def __init__(self, image_feature_dim, num_classes):\n",
    "        super(AdaptiveAttentionClassifier, self).__init__()\n",
    "        self.image_embed = nn.Linear(image_feature_dim, 128)\n",
    "        self.transformer_encoder = nn.ModuleList([\n",
    "            AdaptiveTransformerEncoderLayer(d_model=128, nhead=8) for _ in range(1)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_features):\n",
    "        # Proyección de características\n",
    "        image_embeddings = self.image_embed(image_features)\n",
    "\n",
    "        # Pasar por las capas del Transformer\n",
    "        for layer in self.transformer_encoder:\n",
    "            image_embeddings = layer(image_embeddings.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Clasificador final\n",
    "        output = self.mlp(image_embeddings)\n",
    "        return output\n",
    "\n",
    "# Obtener el directorio actual\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory[:-3], 'data')\n",
    "images_directory = os.path.join(data_directory, 'images')\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "image_feature_dim = 2048\n",
    "\n",
    "subset = [os.path.splitext(filename)[0] for filename in os.listdir(images_directory)]\n",
    "print(len(subset))\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Leer y filtrar datos\n",
    "train_1 = pd.read_csv(f'{data_directory}/train_data.csv')\n",
    "test_1 = pd.read_csv(f'{data_directory}/test_data.csv')\n",
    "\n",
    "train_1 = train_1[train_1['ID'].isin(subset[:500])]\n",
    "test_1 = test_1[test_1['ID'].isin(subset[:500])]\n",
    "\n",
    "# Guardar los archivos filtrados\n",
    "train_1.to_csv(f'{data_directory}/train_data_2.csv', encoding = 'utf-8', index=False)\n",
    "train_1.to_csv(f'{data_directory}/test_data_2.csv', encoding = 'utf-8', index=False)\n",
    "\n",
    "# Crear datasets y DataLoaders\n",
    "train_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/train_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "test_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/test_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "#resnet = models.resnet101(weights=ResNet101_Weights.DEFAULT)  # Para ResNet101\n",
    "#resnet = models.resnet152(weights=ResNet152_Weights.DEFAULT)  # Para ResNet152\n",
    "\n",
    "# Congelar todas las capas inicialmente\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar las capas que quieres ajustar (por ejemplo, 'layer4' o 'fc')\n",
    "for param in resnet.layer4.parameters():  # Afinar el bloque final\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Reemplazar la capa final con una capa adaptada a tu número de clases\n",
    "num_classes = train_dataset[0][1].size(0)  # Obtener el número de clases desde el dataset\n",
    "resnet.fc = nn.Identity()\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "model = AdaptiveAttentionClassifier(image_feature_dim=image_feature_dim, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=lr)\n",
    "\n",
    "#Comprobar que las dimensiones de salida de resnet sean consistentes con la siguiente capa\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "image_features = resnet(images)\n",
    "print(image_features.shape)\n",
    "\n",
    "# Listas para almacenar pérdidas y métricas\n",
    "train_losses = list()\n",
    "val_losses = list()\n",
    "train_accuracies = list()\n",
    "val_accuracies = list()\n",
    "train_f1_scores = list()\n",
    "val_f1_scores = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calcular predicciones para métricas\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "        all_train_labels.append(labels.cpu().numpy())\n",
    "        all_train_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para entrenamiento\n",
    "    all_train_labels = np.vstack(all_train_labels)\n",
    "    all_train_preds = np.vstack(all_train_preds)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            image_features = resnet(images).flatten(start_dim=1)\n",
    "            outputs = model(image_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calcular predicciones para métricas\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "            all_val_labels.append(labels.cpu().numpy())\n",
    "            all_val_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para validación\n",
    "    all_val_labels = np.vstack(all_val_labels)\n",
    "    all_val_preds = np.vstack(all_val_preds)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Imprimir métricas\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "        f\"Train Acc: {train_accuracies[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}, \"\n",
    "        f\"Train F1: {train_f1_scores[-1]:.4f}, Val F1: {val_f1_scores[-1]:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # Coloca el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Listas para almacenar etiquetas reales y predicciones\n",
    "all_labels = list()\n",
    "all_preds = list()\n",
    "\n",
    "# Realizar inferencia\n",
    "with torch.no_grad():  # No calculamos gradientes\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Extraer características con ResNet y pasar por el modelo\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        # Aplicar sigmoid para obtener probabilidades\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convertir probabilidades en predicciones binarias (umbral = 0.5)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        # Guardar etiquetas reales y predicciones\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "# Convertir listas a arreglos\n",
    "all_labels = np.vstack(all_labels)  # Etiquetas reales\n",
    "all_preds = np.vstack(all_preds)    # Predicciones\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=1)\n",
    "# Calcular matriz de confusión para cada etiqueta\n",
    "confusion_matrices = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'test_accuracy: {test_accuracy}, test_f1: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "torch.Size([32, 2048])\n",
      "Epoch 1/10, Train Loss: 0.6018, Val Loss: 0.5303, Train Acc: 0.0054, Val Acc: 0.0536, Train F1: 0.0518, Val F1: 0.0504\n",
      "Epoch 2/10, Train Loss: 0.5039, Val Loss: 0.4691, Train Acc: 0.0375, Val Acc: 0.0188, Train F1: 0.0894, Val F1: 0.1599\n",
      "Epoch 3/10, Train Loss: 0.4657, Val Loss: 0.4462, Train Acc: 0.0027, Val Acc: 0.0027, Train F1: 0.1566, Val F1: 0.1508\n",
      "Epoch 4/10, Train Loss: 0.4511, Val Loss: 0.4354, Train Acc: 0.0080, Val Acc: 0.0027, Train F1: 0.1564, Val F1: 0.2008\n",
      "Epoch 5/10, Train Loss: 0.4437, Val Loss: 0.4295, Train Acc: 0.0188, Val Acc: 0.0054, Train F1: 0.2071, Val F1: 0.2025\n",
      "Epoch 6/10, Train Loss: 0.4394, Val Loss: 0.4256, Train Acc: 0.0188, Val Acc: 0.0161, Train F1: 0.2070, Val F1: 0.2056\n",
      "Epoch 7/10, Train Loss: 0.4357, Val Loss: 0.4217, Train Acc: 0.0349, Val Acc: 0.0268, Train F1: 0.2119, Val F1: 0.2119\n",
      "Epoch 8/10, Train Loss: 0.4319, Val Loss: 0.4181, Train Acc: 0.0375, Val Acc: 0.0643, Train F1: 0.2138, Val F1: 0.2208\n",
      "Epoch 9/10, Train Loss: 0.4295, Val Loss: 0.4159, Train Acc: 0.0777, Val Acc: 0.0724, Train F1: 0.2268, Val F1: 0.2234\n",
      "Epoch 10/10, Train Loss: 0.4272, Val Loss: 0.4138, Train Acc: 0.0831, Val Acc: 0.1340, Train F1: 0.2424, Val F1: 0.2364\n",
      "test_accuracy: 0.13404825737265416, test_f1: 0.2363636363636364\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, resnet101, resnet152, ResNet50_Weights,ResNet101_Weights, ResNet152_Weights\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizar una matriz de confusión para una etiqueta específica\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from SupportFunc.Loader import MultiLabelImageDataset\n",
    "from SupportFunc.AdaptiveAttention_c1 import AdaptiveAttention, AdaptiveTransformerEncoderLayer\n",
    "from SupportFunc.Visualization import plot_confusion_matrix, plot_train_val_curve\n",
    "\n",
    "class AdaptiveAttentionClassifier(nn.Module):\n",
    "    def __init__(self, image_feature_dim, num_classes):\n",
    "        super(AdaptiveAttentionClassifier, self).__init__()\n",
    "        self.image_embed = nn.Linear(image_feature_dim, 256)\n",
    "        self.transformer_encoder = nn.ModuleList([\n",
    "            AdaptiveTransformerEncoderLayer(d_model=256, nhead=8) for _ in range(1)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_features):\n",
    "        # Proyección de características\n",
    "        image_embeddings = self.image_embed(image_features)\n",
    "\n",
    "        # Pasar por las capas del Transformer\n",
    "        for layer in self.transformer_encoder:\n",
    "            image_embeddings = layer(image_embeddings.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Clasificador final\n",
    "        output = self.mlp(image_embeddings)\n",
    "        return output\n",
    "\n",
    "# Obtener el directorio actual\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory[:-3], 'data')\n",
    "images_directory = os.path.join(data_directory, 'images')\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "image_feature_dim = 2048\n",
    "\n",
    "subset = [os.path.splitext(filename)[0] for filename in os.listdir(images_directory)]\n",
    "print(len(subset))\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Leer y filtrar datos\n",
    "train_1 = pd.read_csv(f'{data_directory}/train_data.csv')\n",
    "test_1 = pd.read_csv(f'{data_directory}/test_data.csv')\n",
    "\n",
    "train_1 = train_1[train_1['ID'].isin(subset[:500])]\n",
    "test_1 = test_1[test_1['ID'].isin(subset[:500])]\n",
    "\n",
    "# Guardar los archivos filtrados\n",
    "train_1.to_csv(f'{data_directory}/train_data_2.csv', encoding = 'utf-8', index=False)\n",
    "train_1.to_csv(f'{data_directory}/test_data_2.csv', encoding = 'utf-8', index=False)\n",
    "\n",
    "# Crear datasets y DataLoaders\n",
    "train_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/train_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "test_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/test_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "#resnet = models.resnet101(weights=ResNet101_Weights.DEFAULT)  # Para ResNet101\n",
    "#resnet = models.resnet152(weights=ResNet152_Weights.DEFAULT)  # Para ResNet152\n",
    "\n",
    "# Congelar todas las capas inicialmente\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar las capas que quieres ajustar (por ejemplo, 'layer4' o 'fc')\n",
    "for param in resnet.layer4.parameters():  # Afinar el bloque final\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Reemplazar la capa final con una capa adaptada a tu número de clases\n",
    "num_classes = train_dataset[0][1].size(0)  # Obtener el número de clases desde el dataset\n",
    "resnet.fc = nn.Identity()\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "model = AdaptiveAttentionClassifier(image_feature_dim=image_feature_dim, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=lr)\n",
    "\n",
    "#Comprobar que las dimensiones de salida de resnet sean consistentes con la siguiente capa\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "image_features = resnet(images)\n",
    "print(image_features.shape)\n",
    "\n",
    "# Listas para almacenar pérdidas y métricas\n",
    "train_losses = list()\n",
    "val_losses = list()\n",
    "train_accuracies = list()\n",
    "val_accuracies = list()\n",
    "train_f1_scores = list()\n",
    "val_f1_scores = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calcular predicciones para métricas\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "        all_train_labels.append(labels.cpu().numpy())\n",
    "        all_train_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para entrenamiento\n",
    "    all_train_labels = np.vstack(all_train_labels)\n",
    "    all_train_preds = np.vstack(all_train_preds)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            image_features = resnet(images).flatten(start_dim=1)\n",
    "            outputs = model(image_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calcular predicciones para métricas\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "            all_val_labels.append(labels.cpu().numpy())\n",
    "            all_val_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para validación\n",
    "    all_val_labels = np.vstack(all_val_labels)\n",
    "    all_val_preds = np.vstack(all_val_preds)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Imprimir métricas\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "        f\"Train Acc: {train_accuracies[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}, \"\n",
    "        f\"Train F1: {train_f1_scores[-1]:.4f}, Val F1: {val_f1_scores[-1]:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # Coloca el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Listas para almacenar etiquetas reales y predicciones\n",
    "all_labels = list()\n",
    "all_preds = list()\n",
    "\n",
    "# Realizar inferencia\n",
    "with torch.no_grad():  # No calculamos gradientes\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Extraer características con ResNet y pasar por el modelo\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        # Aplicar sigmoid para obtener probabilidades\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convertir probabilidades en predicciones binarias (umbral = 0.5)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        # Guardar etiquetas reales y predicciones\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "# Convertir listas a arreglos\n",
    "all_labels = np.vstack(all_labels)  # Etiquetas reales\n",
    "all_preds = np.vstack(all_preds)    # Predicciones\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=1)\n",
    "# Calcular matriz de confusión para cada etiqueta\n",
    "confusion_matrices = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'test_accuracy: {test_accuracy}, test_f1: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "torch.Size([32, 2048])\n",
      "Epoch 1/10, Train Loss: 0.6148, Val Loss: 0.5244, Train Acc: 0.0054, Val Acc: 0.0483, Train F1: 0.0813, Val F1: 0.2129\n",
      "Epoch 2/10, Train Loss: 0.4826, Val Loss: 0.4367, Train Acc: 0.0697, Val Acc: 0.1340, Train F1: 0.2407, Val F1: 0.2378\n",
      "Epoch 3/10, Train Loss: 0.4237, Val Loss: 0.3931, Train Acc: 0.1126, Val Acc: 0.1099, Train F1: 0.2384, Val F1: 0.2361\n",
      "Epoch 4/10, Train Loss: 0.3941, Val Loss: 0.3725, Train Acc: 0.1019, Val Acc: 0.0536, Train F1: 0.2264, Val F1: 0.2222\n",
      "Epoch 5/10, Train Loss: 0.3786, Val Loss: 0.3602, Train Acc: 0.0429, Val Acc: 0.0107, Train F1: 0.2156, Val F1: 0.2048\n",
      "Epoch 6/10, Train Loss: 0.3688, Val Loss: 0.3521, Train Acc: 0.0402, Val Acc: 0.0456, Train F1: 0.2128, Val F1: 0.2185\n",
      "Epoch 7/10, Train Loss: 0.3627, Val Loss: 0.3465, Train Acc: 0.0590, Val Acc: 0.0563, Train F1: 0.2200, Val F1: 0.2227\n",
      "Epoch 8/10, Train Loss: 0.3572, Val Loss: 0.3421, Train Acc: 0.0831, Val Acc: 0.1072, Train F1: 0.2278, Val F1: 0.2313\n",
      "Epoch 9/10, Train Loss: 0.3528, Val Loss: 0.3384, Train Acc: 0.1072, Val Acc: 0.1072, Train F1: 0.2326, Val F1: 0.2314\n",
      "Epoch 10/10, Train Loss: 0.3498, Val Loss: 0.3353, Train Acc: 0.1448, Val Acc: 0.1340, Train F1: 0.2384, Val F1: 0.2367\n",
      "test_accuracy: 0.13404825737265416, test_f1: 0.23668341708542712\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, resnet101, resnet152, ResNet50_Weights,ResNet101_Weights, ResNet152_Weights\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizar una matriz de confusión para una etiqueta específica\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from SupportFunc.Loader import MultiLabelImageDataset\n",
    "from SupportFunc.AdaptiveAttention_c1 import AdaptiveAttention, AdaptiveTransformerEncoderLayer\n",
    "from SupportFunc.Visualization import plot_confusion_matrix, plot_train_val_curve\n",
    "\n",
    "class AdaptiveAttentionClassifier(nn.Module):\n",
    "    def __init__(self, image_feature_dim, num_classes):\n",
    "        super(AdaptiveAttentionClassifier, self).__init__()\n",
    "        self.image_embed = nn.Linear(image_feature_dim, 512)\n",
    "        self.transformer_encoder = nn.ModuleList([\n",
    "            AdaptiveTransformerEncoderLayer(d_model=512, nhead=8) for _ in range(1)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_features):\n",
    "        # Proyección de características\n",
    "        image_embeddings = self.image_embed(image_features)\n",
    "\n",
    "        # Pasar por las capas del Transformer\n",
    "        for layer in self.transformer_encoder:\n",
    "            image_embeddings = layer(image_embeddings.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Clasificador final\n",
    "        output = self.mlp(image_embeddings)\n",
    "        return output\n",
    "\n",
    "# Obtener el directorio actual\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory[:-3], 'data')\n",
    "images_directory = os.path.join(data_directory, 'images')\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "image_feature_dim = 2048\n",
    "\n",
    "subset = [os.path.splitext(filename)[0] for filename in os.listdir(images_directory)]\n",
    "print(len(subset))\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Leer y filtrar datos\n",
    "train_1 = pd.read_csv(f'{data_directory}/train_data.csv')\n",
    "test_1 = pd.read_csv(f'{data_directory}/test_data.csv')\n",
    "\n",
    "train_1 = train_1[train_1['ID'].isin(subset[:500])]\n",
    "test_1 = test_1[test_1['ID'].isin(subset[:500])]\n",
    "\n",
    "# Guardar los archivos filtrados\n",
    "train_1.to_csv(f'{data_directory}/train_data_2.csv', encoding = 'utf-8', index=False)\n",
    "train_1.to_csv(f'{data_directory}/test_data_2.csv', encoding = 'utf-8', index=False)\n",
    "\n",
    "# Crear datasets y DataLoaders\n",
    "train_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/train_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "test_dataset = MultiLabelImageDataset(csv_file=f\"{data_directory}/test_data_2.csv\", img_dir=f\"{images_directory}/\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "#resnet = models.resnet101(weights=ResNet101_Weights.DEFAULT)  # Para ResNet101\n",
    "#resnet = models.resnet152(weights=ResNet152_Weights.DEFAULT)  # Para ResNet152\n",
    "\n",
    "# Congelar todas las capas inicialmente\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar las capas que quieres ajustar (por ejemplo, 'layer4' o 'fc')\n",
    "for param in resnet.layer4.parameters():  # Afinar el bloque final\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Reemplazar la capa final con una capa adaptada a tu número de clases\n",
    "num_classes = train_dataset[0][1].size(0)  # Obtener el número de clases desde el dataset\n",
    "resnet.fc = nn.Identity()\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "model = AdaptiveAttentionClassifier(image_feature_dim=image_feature_dim, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=lr)\n",
    "\n",
    "#Comprobar que las dimensiones de salida de resnet sean consistentes con la siguiente capa\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "image_features = resnet(images)\n",
    "print(image_features.shape)\n",
    "\n",
    "# Listas para almacenar pérdidas y métricas\n",
    "train_losses = list()\n",
    "val_losses = list()\n",
    "train_accuracies = list()\n",
    "val_accuracies = list()\n",
    "train_f1_scores = list()\n",
    "val_f1_scores = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calcular predicciones para métricas\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "        all_train_labels.append(labels.cpu().numpy())\n",
    "        all_train_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para entrenamiento\n",
    "    all_train_labels = np.vstack(all_train_labels)\n",
    "    all_train_preds = np.vstack(all_train_preds)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            image_features = resnet(images).flatten(start_dim=1)\n",
    "            outputs = model(image_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calcular predicciones para métricas\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()  # Umbral de 0.5 para predicciones binarias\n",
    "            all_val_labels.append(labels.cpu().numpy())\n",
    "            all_val_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Calcular métricas para validación\n",
    "    all_val_labels = np.vstack(all_val_labels)\n",
    "    all_val_preds = np.vstack(all_val_preds)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Imprimir métricas\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "        f\"Train Acc: {train_accuracies[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}, \"\n",
    "        f\"Train F1: {train_f1_scores[-1]:.4f}, Val F1: {val_f1_scores[-1]:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # Coloca el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Listas para almacenar etiquetas reales y predicciones\n",
    "all_labels = list()\n",
    "all_preds = list()\n",
    "\n",
    "# Realizar inferencia\n",
    "with torch.no_grad():  # No calculamos gradientes\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Extraer características con ResNet y pasar por el modelo\n",
    "        image_features = resnet(images).flatten(start_dim=1)\n",
    "        outputs = model(image_features)\n",
    "\n",
    "        # Aplicar sigmoid para obtener probabilidades\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convertir probabilidades en predicciones binarias (umbral = 0.5)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        # Guardar etiquetas reales y predicciones\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "# Convertir listas a arreglos\n",
    "all_labels = np.vstack(all_labels)  # Etiquetas reales\n",
    "all_preds = np.vstack(all_preds)    # Predicciones\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=1)\n",
    "# Calcular matriz de confusión para cada etiqueta\n",
    "confusion_matrices = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'test_accuracy: {test_accuracy}, test_f1: {test_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
